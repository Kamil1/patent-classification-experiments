{
  "total_runtime": 65.50744819641113,
  "model_loading_time": 15.006368160247803,
  "inference_time": 48.72616124153137,
  "preprocessing_time": 0.0,
  "total_input_tokens": 1138,
  "total_output_tokens": 14,
  "avg_input_tokens": 379.3333333333333,
  "avg_output_tokens": 4.666666666666667,
  "peak_cpu_percent": 100.0,
  "avg_cpu_percent": 76.46666666666665,
  "peak_memory_mb": 6155.15625,
  "avg_memory_mb": 4835.035037878788,
  "peak_gpu_memory_mb": 0.0,
  "avg_gpu_memory_mb": 0.0,
  "estimated_compute_cost_usd": 0.0,
  "estimated_token_cost_usd": 0.00017909999999999996,
  "total_estimated_cost_usd": 0.00017909999999999996,
  "samples_processed": 3,
  "samples_per_second": 0.045796319084283256,
  "cost_per_sample_usd": 5.969999999999999e-05,
  "model_name": "meta-llama/Llama-3.1-8B-Instruct",
  "batch_size": 4,
  "max_length": 2048,
  "quantization": "none",
  "timestamp": "2025-10-10T10:48:31.694325"
}