{
  "total_runtime": 1831.9019329547882,
  "model_loading_time": 0.0,
  "inference_time": 0.0,
  "preprocessing_time": 0.0,
  "total_input_tokens": 1166426,
  "total_output_tokens": 24249,
  "avg_input_tokens": 233.2852,
  "avg_output_tokens": 4.8498,
  "peak_cpu_percent": 27.1,
  "avg_cpu_percent": 10.822929237520553,
  "peak_memory_mb": 6365.0546875,
  "avg_memory_mb": 6165.712330293472,
  "peak_gpu_memory_mb": 0.0,
  "avg_gpu_memory_mb": 0.0,
  "estimated_compute_cost_usd": 0.0,
  "estimated_token_cost_usd": 0.18951329999999997,
  "total_estimated_cost_usd": 0.18951329999999997,
  "samples_processed": 5000,
  "samples_per_second": 2.7294037470309287,
  "cost_per_sample_usd": 3.7902659999999996e-05,
  "model_name": "meta-llama/Llama-3.1-8B-Instruct",
  "batch_size": 4,
  "max_length": 2048,
  "quantization": "4bit-modal-generative",
  "timestamp": "2025-10-21T19:46:53.081684"
}